regression_names = c("baseline", "add", "replace")
dll_raw_df = data.frame()
for (lang in langs) {
print(paste0("Fitting model for ", lang))
df = read.csv(paste0("../data/merged_data/", lang, ".csv")) %>%
filter(freq > 0, prev_freq > 0, prev2_freq > 0) %>%
filter(is.finite(freq) & is.finite(prev_freq) & is.finite(prev2_freq))
for (m in models) {
df_eval = df %>% filter(model == m) %>%
drop_na()
for (psychometric in psychometrics) {
regression_forms = c(
paste0(psychometric, " ~ surp + prev_surp + prev2_surp + freq + len + prev_freq + prev_len + prev2_freq + prev2_len"),
paste0(psychometric, " ~ ent + prev_ent + prev2_ent + surp + prev_surp + prev2_surp + freq + len + prev_freq + prev_len + prev2_freq + prev2_len"),
paste0(psychometric, " ~ ent + prev_ent + prev2_ent + freq + len + prev_freq + prev_len + prev2_freq + prev2_len")
)
loglik_df = data.frame(names=regression_names, forms=regression_forms) %>%
mutate(logliks = map(regression_forms, model_cross_val, df=df_eval, d_var=psychometric, mixed_effects = F )) %>%
dplyr::select(-forms)
loglik_df = loglik_df %>% unnest(cols = c(logliks)) %>% mutate(lang = lang, psychometric = psychometric, model = m)
dll_raw_df = rbind(dll_raw_df, loglik_df)
}
}
}
comps = c("add", "replace")
dll_xlang_ent_df = data.frame()
for(l in langs){
print(paste0("Tests for ", l))
for (ps in psychometrics){
for(c in comps){
for(m in models) {
if(c != "baseline") {
target_df = dll_raw_df %>% filter(psychometric == ps, names == c, lang == l, model == m)
baseline_df = dll_raw_df %>% filter(psychometric == ps, names == "baseline", lang == l, model == m)
dll = target_df$logliks - baseline_df$logliks
dll = dll[!is.na(dll)]
ttest = perm.test(dll, num.sim = 500)
dll_df = data.frame(comp = c, mean = mean(dll), upper = mean(dll) + (1.96 * std.error(dll)),
lower = mean(dll) - (1.96 * std.error(dll)), ttest_pval = ttest$p.value,
lang = l, psychometric = ps, model = m)
dll_xlang_ent_df = rbind(dll_xlang_ent_df, dll_df)
}
}
}
}
}
dll_agg_ent_df = data.frame()
for (ps in psychometrics){
for(c in comps){
for(m in models){
if(c != "baseline") {
target_df = dll_raw_df %>% filter(psychometric == ps, names == c, model == m)
baseline_df = dll_raw_df %>% filter(psychometric == ps, names == "baseline", model == m)
dll = target_df$logliks - baseline_df$logliks
dll = dll[!is.na(dll)]
ttest = perm.test(dll, num.sim = 500)
dll_df = data.frame(comp = c, mean = mean(dll), upper = mean(dll) + (1.96 * std.error(dll)),
lower = mean(dll) - (1.96 * std.error(dll)), ttest_pval = ttest$p.value,
lang = "All", psychometric = ps, model = m)
dll_agg_ent_df = rbind(dll_agg_ent_df, dll_df)
}
}
}
}
# Merge the dataframes
dll_ent_plotting_df = rbind(dll_xlang_ent_df, dll_agg_ent_df)
dll_ent_plotting_df %>%
mutate(lang = factor(lang, levels = c("All", "du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"),
labels = c("All", "Dutch", "English", "Finnish", "German", "Greek", "Hebrew", "Italian", "Korean", "Russian",
"Spanish", "Turkish"))) %>%
filter(model %in% c("mgpt_lc", "monot_all")) %>%
rename(target = comp) %>%
mutate(sig = case_when( ttest_pval >= 0.05 ~ " ",
ttest_pval < 0.05 & ttest_pval >= 0.01  ~ "*",
ttest_pval < 0.01 & ttest_pval >= 0.001  ~ "**",
ttest_pval < 0.001  ~ "***")) %>%
mutate(psychometric = case_when(psychometric == "firstfix_rt" ~ "First Fixation",
psychometric == "gaze_rt" ~ "Gaze Duration",
psychometric == "total_rt" ~ "Total Fixation")) %>%
mutate(model = if_else(model == "mgpt_lc", "mGPT", "monoT (all)")) %>%
mutate(target = if_else(target == "add", "Add Entropy", "Replace Surprisal w/ Entropy")) %>%
ggplot(aes(x = psychometric, y = mean, color = psychometric, shape = target, alpha=target)) +
geom_hline(yintercept=0, color="black", linetype="dashed", alpha =0.5) +
geom_point(position = position_dodge(width = 0.6) ) +
geom_text(aes(y = if_else(target == "Add Entropy", 0.03, -0.067), label = sig), size = 3, show.legend = FALSE) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.1, position = position_dodge(width = 0.6)) +
ylab("Delta Log Likelihood (average per word)") +
xlab("") +
facet_grid(model~lang) +
scale_x_discrete(labels = c("FF", "GD", "TF")) +
scale_alpha_discrete(range = c(1, 0.5)) +
#scale_color_manual(values = c("#a1dab4", "#41b6c4", "#225ea8")) +
#ggtitle("Contribution of Surprisal to Î”LL") +
theme(
legend.position = "bottom",
axis.title.x = element_blank(),
axis.text.x = element_text(size = 7),
legend.title = element_blank(),
text = element_text(family = "serif")
#panel.border = element_rect(color = "grey", fill =  NA, size = 0.5)
)
ggsave("./images/dll_ent.pdf", device="pdf", width = 8.5, height = 4)
regression_names = c("add", "replace", "baseline")
df_all_langs = data.frame()
for (lang in langs) {
df = read.csv(paste0("../data/merged_data/", lang, ".csv")) %>%
filter(freq > 0, prev_freq > 0, prev2_freq > 0) %>%
filter(is.finite(freq) & is.finite(prev_freq) & is.finite(prev2_freq)) %>%
mutate(lang = as.factor(lang))
df_all_langs = rbind(df_all_langs, df)
}
#Scale things due to convergence issues w/ the random effects
#df_all_langs = df_all_langs %>%
#group_by(model) %>%
#mutate(surp = scale(surp), len = scale(len), freq = scale(freq), gaze_rt = scale(gaze_rt), firstfix_rt = scale(firstfix_rt), total_rt = scale(total_rt)) %>%
#ungroup()
df_all_langs= df_all_langs[sample(1:nrow(df_all_langs)), ]
dll_raw_df = data.frame()
for (m in models){
for (psychometric in c("gaze_rt")) {
regression_forms = c(
paste0(psychometric, " ~ ent + prev_ent + surp + prev_surp + freq + len + prev_freq + prev_len + (ent + surp + freq + len | lang)"),
paste0(psychometric, " ~ ent + prev_ent + freq + len + prev_freq + prev_len + (ent + freq + len | lang)"),
paste0(psychometric, " ~ surp + prev_surp + freq + len + prev_freq + prev_len + (surp + freq + len | lang)")
)
to_fit_df = df_all_langs %>% filter(model == m) %>% drop_na()
loglik_df = data.frame(names=regression_names, forms=regression_forms) %>%
mutate(logliks = map(regression_forms, model_cross_val, df=to_fit_df, d_var=psychometric, mixed_effects=T )) %>%
dplyr::select(-forms)
loglik_df = loglik_df %>% unnest(cols = c(logliks)) %>% mutate(psychometric = psychometric, model = m)
dll_raw_df = rbind(dll_raw_df, loglik_df)
}
}
shhh <- suppressPackageStartupMessages # It's a library, so shhh!
shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))
library(jmuOutlier) # For paired permutation tests
#options(JULIA_HOME = "/Applications/Julia-1.8.app/Contents/Resources/julia/bin/")
#library(jglmm)
#jglmm_setup()
theme_set(theme_bw())
options(digits=4)
options(dplyr.summarise.inform = FALSE)
set.seed(444)
langs = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "sp", "tr", "ru")
models = c("mgpt_sc", "mgpt_lc", "monot_30m", "monot_all")
comps = c("target", "baseline")
psychometric = "gaze_rt" # We're only gonna look at one psychometric here
model_cross_val = function(form, df, d_var, num_folds=10){
folds <- cut(seq(1,nrow(df)),breaks=num_folds,labels=FALSE)
estimates <- c()
models <- c()
for(i in 1:num_folds){
testIndexes = which(folds==i,arr.ind=TRUE)
testData = df[testIndexes,]
trainData = df[-testIndexes,]
if(grepl("bs = 'cr'", form, fixed=TRUE)) {
model = gam(as.formula(form), data = trainData)
} else {
model = lm(as.formula(form), data = trainData)
}
stdev = sigma(model)
densities <- log(dnorm(testData[[d_var]],
mean=predict(model, newdata=testData),
sd=stdev))
estimates <- c(estimates, densities)
}
return(estimates)
}
regression_names = c("linear_baseline", "linear_target", "nonlinear_baseline", "nonlinear_target")
dll_raw_df = data.frame()
for (lang in langs) {
print(paste0("Fitting model for ", lang))
for(m in models){
df = read.csv(paste0("../data/merged_data/", lang, ".csv")) %>%
filter(freq > 0, prev_freq > 0, prev2_freq > 0) %>%
filter(is.finite(freq) & is.finite(prev_freq) & is.finite(prev2_freq)) %>%
filter(model == m)
regression_forms = c(
# Linear Models
#paste0(psychometric, " ~ freq + prev_freq + len + prev_len"),
paste0(psychometric, " ~ te(freq, len, bs = 'cr') + te(prev_freq, prev_len, bs = 'cr')"),
paste0(psychometric, "~ surp + prev_surp + te(freq, len, bs = 'cr') + te(prev_freq, prev_len, bs = 'cr') "),
# Non-Linear Models
paste0(psychometric, " ~ te(freq, len, bs = 'cr') + te(prev_freq, prev_len, bs = 'cr')"),
paste0(psychometric, "~ s(surp, bs = 'cr', k = 6) + s(prev_surp, bs = 'cr', k = 6) + te(freq, len, bs = 'cr') + te(prev_freq, prev_len, bs = 'cr') ")
)
loglik_df = data.frame(names=regression_names, forms=regression_forms) %>%
mutate(logliks = map(regression_forms, model_cross_val, df=df, d_var=psychometric )) %>%
dplyr::select(-forms)
loglik_df = loglik_df %>% unnest(cols = c(logliks)) %>% mutate(lang = lang, psychometric = psychometric, model = m)
dll_raw_df = rbind(dll_raw_df, loglik_df)
}
}
dll_stats_df = data.frame()
for (m in models){
for(l in langs){
target_df_linear = dll_raw_df %>% filter(model == m, lang == l, names == "linear_target")
baseline_df_linear = dll_raw_df %>% filter(model == m, lang == l, names == "linear_baseline")
dll_linear = target_df_linear$logliks - baseline_df_linear$logliks
dll_stats_df = rbind(dll_stats_df, data.frame(dll = dll_linear, linear="linear", model = m, lang = l))
target_df_nonlinear = dll_raw_df %>% filter(model == m, lang == l, names == "nonlinear_target")
baseline_df_nonlinear = dll_raw_df %>% filter(model == m, lang == l, names == "nonlinear_baseline")
dll_nonlinear = target_df_nonlinear$logliks- baseline_df_nonlinear$logliks
dll_stats_df = rbind(dll_stats_df, data.frame(dll = dll_nonlinear, linear = "non-linear", model = m, lang = l))
}
}
dll_stats_cleaned_df = dll_stats_df %>%
drop_na() %>%
group_by(model, lang) %>%
mutate(m = mean(dll), s = sd(dll))%>%
ungroup() %>%
filter(dll < m + s * 3,
dll > m - s * 3)
dll_stats_cleaned_df %>%
group_by(lang, model) %>%
summarise(
m = mean(dll),
pval = perm.test(dll, num.sim = 500)$p.value) %>%
ungroup()
linear_comp_df = data.frame()
for (m in models){
for(l in langs){
target_df_linear = dll_raw_df %>% filter(model == m, lang == l, names == "linear_target")
baseline_df_linear = dll_raw_df %>% filter(model == m, lang == l, names == "linear_baseline")
dll_linear = data.frame(dll = target_df_linear$logliks - baseline_df_linear$logliks) %>%
drop_na() %>%
mutate( m = mean(dll), s=sd(dll)) %>%
filter(dll < m + s * 3, dll > m - s * 3)
dll_linear = dll_linear$dll
#dll_linear = dll_linear[!is.na(dll_linear)]
linear_ttest = perm.test(dll_linear, num.sim = 1)
target_df_nonlinear = dll_raw_df %>% filter(model == m, lang == l, names == "nonlinear_target")
baseline_df_nonlinear = dll_raw_df %>% filter(model == m, lang == l, names == "nonlinear_baseline")
dll_nonlinear = data.frame(dll = target_df_nonlinear$logliks- baseline_df_nonlinear$logliks) %>%
drop_na() %>%
mutate( m = mean(dll), s=sd(dll)) %>%
filter(dll < m + s * 3, dll > m - s * 3)
dll_nonlinear = dll_nonlinear$dll
#dll_nonlinear = dll_nonlinear[!is.na(dll_nonlinear)]
nonlinear_ttest = perm.test(dll_nonlinear, num.sim = 1)
comp_ttest = perm.test(dll_nonlinear, dll_linear, num.sim = 500)
dll_df_linear = data.frame(
m = mean(dll_linear), upper = mean(dll_linear) + (1.96 * std.error(dll_linear)), lower = mean(dll_linear) - (1.96 * std.error(dll_linear)),
ttest_pval = linear_ttest$p.value,
#Comparison information
ttest_pval_comp = comp_ttest$p.value,
# Meta info
lang = l, model = m, is_linear = "linear"
)
dll_df_nonlinear = data.frame(
m = mean(dll_nonlinear), upper = mean(dll_nonlinear) + (1.96 * std.error(dll_nonlinear)), lower = mean(dll_nonlinear) - (1.96 * std.error(dll_nonlinear)), ttest_pval = nonlinear_ttest$p.value,
#Comparison information
ttest_pval_comp = comp_ttest$p.value,
# Meta info
lang = l, model = m, is_linear = "nonlinear"
)
dll_df = rbind(dll_df_linear, dll_df_nonlinear)
linear_comp_df = rbind(linear_comp_df, dll_df)
}
}
linear_comp_df %>%
mutate(is_linear = if_else(is_linear == "linear", "Linear", "Non-linear")) %>%
#mutate(context = if_else(context == "long", "Long Context", "Short Context")) %>%
ggplot(aes(x = lang, y = m, color = is_linear, shape = is_linear)) +
#geom_hline(yintercept=0, color = "blue") +
geom_point(position = position_dodge(width = 0.5)) +
geom_errorbar(aes(ymin = lower, ymax= upper, width = 0.1), position = position_dodge(width = 0.5)) +
facet_grid(model~., labeller = labeller(model = as_labeller(c(mgpt_lc="mGPT\n(long)", mgpt_sc="mGPT\n(short)", monot_30m="monoT\n(30m)", monot_all="monoT\n(all)")))) +
scale_color_manual(name="Model Type", labels=c("Linear", "Non-linear"), values = c("#6488d6", "#29bc8b")) +
scale_shape_manual(name="Model Type", labels=c("Linear", "Non-linear"), values = c(19, 17)) +
ylab("Delta Log Liklihood (per word)") +
#labs(color = "Model Type") +
#scale_shape(guide = "none") +
theme(
legend.position = "bottom",
axis.title.x = element_blank()
)
ggsave("./images/dll_linear_comp.pdf", device ="pdf", width = 4, height = 4)
fit_gam_inner = function(bootstrap_sample, mean_predictors, is_linear) {
df = bootstrap_sample$data
weights = tabulate(as.integer(bootstrap_sample), nrow(df))
if (is_linear) {
m = gam(psychometric ~ surp + prev_surp + te(freq, len, bs = 'cr') + te(prev_freq, prev_len, bs = 'cr'), data = df, weights = weights)
terms_to_predict = c("surp", "prev_surp")
} else {
m = gam(psychometric ~ s(surp, bs = 'cr', k = 6) + s(prev_surp, bs = 'cr', k = 6) + te(freq, len, bs = 'cr') + te(prev_freq, prev_len, bs = 'cr'), data = df, weights = weights)
terms_to_predict = c("s(surp)", "s(prev_surp)")
}
newdata = data.frame(surp=mean_predictors$surp,
prev_surp=seq(0,20,by=0.1),
freq=mean_predictors$freq, prev_freq=mean_predictors$freq,
len=mean_predictors$freq, prev_len=mean_predictors$freq)
# Returns a matrix N_samples * N_terms.
per_term_predictions = predict(m, newdata=newdata, terms=terms_to_predict, type="terms")
# Additive model -- sum across predictor response contributions (matrix columns).
predictions = rowSums(per_term_predictions)
return(newdata %>% mutate(y=predictions))
}
fit_gam = function(df, mean_predictors, is_linear, alpha=0.05) {
# Bootstrap-resample data
boot_models = df %>% bootstraps(times=10) %>%
# Fit a GAM and get predictions for each sample
mutate(smoothed=map(splits, fit_gam_inner, mean_predictors=mean_predictors, is_linear = is_linear))
# Extract mean and 5% and 95% percentile y-values for each surprisal value
result = boot_models %>%
unnest(smoothed) %>%
dplyr::select(prev_surp, y) %>%
group_by(prev_surp) %>%
summarise(y_lower=quantile(y, alpha / 2),
y_upper=quantile(y, 1 - alpha / 2),
y=mean(y)) %>%
ungroup()
return (result)
}
xlang_linear_smooths = data.frame()
xlang_nonlinear_smooths = data.frame()
models = c("mgpt_lc", "monot_all")
for(m in models){
for (lang in langs) {
print(paste0("Fitting model for ", lang))
merged_df = read.csv(paste0("../data/merged_data/", lang, ".csv")) %>%
filter(freq > 0, prev_freq > 0, prev2_freq > 0) %>%
filter(is.finite(freq) & is.finite(prev_freq) & is.finite(prev2_freq)) %>% rename(psychometric = gaze_rt)
mean_predictors = merged_df %>% summarise(surp = mean(surp), len = mean(len), freq = mean(freq))
smooths = merged_df %>% fit_gam(., mean_predictors, is_linear=T)
#Fix 0 surprisal = 0 ms
gam_smooths = smooths %>% mutate(delta = 0 - y[1], y=y + delta, y_lower= y_lower + delta, y_upper=y_upper + delta)
xlang_linear_smooths = rbind(xlang_linear_smooths, gam_smooths %>% mutate(lang = lang, model = m, linear = "linear"))
}
for (lang in langs) {
print(paste0("Fitting model for ", lang))
merged_df = read.csv(paste0("../data/merged_data/", lang, ".csv")) %>%
filter(freq > 0, prev_freq > 0, prev2_freq > 0) %>%
filter(is.finite(freq) & is.finite(prev_freq) & is.finite(prev2_freq)) %>% rename(psychometric = gaze_rt)
mean_predictors = merged_df %>% summarise(surp = mean(surp), len = mean(len), freq = mean(freq))
smooths = merged_df %>% fit_gam(., mean_predictors, is_linear=F)
#Fix 0 surprisal = 0 ms
gam_smooths = smooths %>% mutate(delta = 0 - y[1], y=y + delta, y_lower= y_lower + delta, y_upper=y_upper + delta)
xlang_nonlinear_smooths = rbind(xlang_nonlinear_smooths, gam_smooths %>% mutate(lang = lang, model = m, linear = "non-linear" ))
}
}
write.csv(xlang_linear_smooths, "./gam_saves/prev_word_nonlinear.csv")
write.csv(xlang_nonlinear_smooths, "./gam_saves/prev_word_linear.csv")
get_d_points = function(df) {
x = density(df$surp)$x
y = density(df$surp)$y
return(data.frame(x, y))
}
density_data = data.frame()
for (m in models){
for(l in langs) {
dummy_df = read.csv(paste0("../data/merged_data/", l, ".csv")) %>% filter(model == m) %>%
do({get_d_points(.)}) %>%
filter(x>0, x<20)
density_data = rbind(density_data, dummy_df %>% mutate(lang = l, model = m))
}}
density_data = density_data %>%
mutate(lang = factor(lang, levels = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"),
labels = c("Dutch", "English", "Finnish", "German", "Greek", "Hebrew", "Italian", "Korean", "Russian",
"Spanish", "Turkish")))
xlang_nonlinear_smooths = read.csv( "./gam_saves/prev_word_nonlinear.csv")%>%
mutate(lang = factor(lang, levels = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"),
labels = c("Dutch", "English", "Finnish", "German", "Greek", "Hebrew", "Italian", "Korean", "Russian",
"Spanish", "Turkish")))
xlang_linear_smooths = read.csv( "./gam_saves/prev_word_linear.csv")%>%
mutate(lang = factor(lang, levels = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"),
labels = c("Dutch", "English", "Finnish", "German", "Greek", "Hebrew", "Italian", "Korean", "Russian",
"Spanish", "Turkish")))
xlang_linear_plot_df = xlang_linear_smooths
xlang_nonlinear_plot_df = xlang_nonlinear_smooths %>%
mutate()
# Surprisal curves for long context
ggplot() +
annotate("rect", xmin=0, xmax=20, ymin=-20,ymax=-8, fill="#f4f4f4", color="grey", alpha=1, size = 0.2) +
geom_line(data = density_data, aes(x=x, y=y*50 - 18), color="#aaaaaa", size = 0.4) +
geom_line(data = xlang_linear_smooths, aes(x=prev_surp, y=y, color = linear), size=0.7) +
geom_line(data = xlang_nonlinear_smooths, aes(x=prev_surp, y=y, color = linear), size=0.5, linetype = "dashed") +
geom_ribbon(data = xlang_nonlinear_smooths, aes(x=prev_surp, ymin=y_lower, ymax=y_upper, fill = linear), alpha=0.3, size=0.5) +
geom_ribbon(data = xlang_linear_smooths, aes(x=prev_surp, ymin=y_lower, ymax=y_upper, fill = linear), alpha=0.3, size=0.5) +
scale_x_continuous(labels=c(0, 10, 20), breaks=c(0, 10, 20), minor_breaks = NULL) +
facet_grid(model~lang, labeller = labeller(model = as_labeller(c(mgpt_lc="mGPT (long)", mgpt_sc="mGPT (short)", monot_30m="monoT (30m)", monot_all="monoT (all)")))) +
ylab("Slowdown due to Surprisal (ms)") +
xlab("Surprisal of Word (bits)") +
#scale_color_manual(values = c("#b7b7b7", "#29bc8b")) +
scale_color_manual(values = c("#6488d6", "#29bc8b")) +
scale_fill_manual(values = c("#6488d6", "#29bc8b")) +
scale_linetype_manual(values = c("a", "b")) +
#ggtitle("Effect of Surprisal on Reading Time across Languages \n Long Context Window")
theme(
legend.position = "none",
panel.grid.minor = element_blank(),
text = element_text(family = "serif")
)
ggsave("./images/prev_surp_link.pdf", device = "pdf", height = 3, width = 8)
linear_comp_df %>%
mutate(lang = factor(lang, levels = c("du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"),
labels = c("Dutch", "English", "Finnish", "German", "Greek", "Hebrew", "Italian", "Korean", "Russian",
"Spanish", "Turkish"))) %>%
mutate(is_linear = if_else(is_linear == "linear", "Linear", "Non-linear")) %>%
#mutate(context = if_else(context == "long", "Long Context", "Short Context")) %>%
ggplot(aes(x = lang, y = m, color = is_linear, shape = is_linear)) +
#geom_hline(yintercept=0, color = "blue") +
geom_point(position = position_dodge(width = 0.5)) +
geom_errorbar(aes(ymin = lower, ymax= upper, width = 0.1), position = position_dodge(width = 0.5)) +
facet_grid(model~., labeller = labeller(model = as_labeller(c(mgpt_lc="mGPT\n(long)", mgpt_sc="mGPT\n(short)", monot_30m="monoT\n(30m)", monot_all="monoT\n(all)")))) +
scale_color_manual(name="Model Type", labels=c("Linear", "Non-linear"), values = c("#6488d6", "#29bc8b")) +
scale_shape_manual(name="Model Type", labels=c("Linear", "Non-linear"), values = c(19, 17)) +
ylab("Delta Log Liklihood (per word)") +
#labs(color = "Model Type") +
#scale_shape(guide = "none") +
theme(
legend.position = "bottom",
axis.title.x = element_blank(),
text = element_text(family = "serif"),
axis.text.x = element_text(angle = 35, hjust = 1)
)
ggsave("./images/dll_linear_comp.pdf", device ="pdf", width = 4, height = 4)
# Merge the dataframes
dll_surp_plotting_df = rbind(dll_xlang_surp_df, dll_agg_surp_df)
options(scipen=999)
dll_surp_plotting_df %>%
mutate(lang = factor(lang, levels = c("All", "du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"),
labels = c("All", "Dutch", "English", "Finnish", "German", "Greek", "Hebrew", "Italian", "Korean", "Russian",
"Spanish", "Turkish"))) %>%
filter(model %in% c("mgpt_lc", "monot_all", "monot_30m")) %>%
filter(comp == "target") %>%
rename(target = comp) %>%
mutate(sig = case_when( ttest_pval >= 0.05 ~ " ",
ttest_pval < 0.05 & ttest_pval >= 0.01  ~ "*",
ttest_pval < 0.01 & ttest_pval >= 0.001  ~ "**",
ttest_pval < 0.001  ~ "***")) %>%
mutate(psychometric = case_when(psychometric == "firstfix_rt" ~ "First Fixation",
psychometric == "gaze_rt" ~ "Gaze Duration",
psychometric == "total_rt" ~ "Total Fixation")) %>%
mutate(model = case_when(model == "mgpt_lc" ~ "mGPT",
model == "monot_all" ~ "monoT (all)",
model == "monot_30m" ~ "monoT (30m)")) %>%
mutate(model = factor(model, levels = c("mGPT", "monoT (all)", "monoT (30m)"))) %>%
ggplot(aes(x = psychometric, y = mean, color = psychometric)) +
geom_hline(yintercept=0, color="black", linetype="dashed", alpha =0.5) +
geom_point(position = position_dodge(width = 0.6)) +
geom_text(aes(y = 0.076, label = sig), size = 3, show.legend = FALSE) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.1, position = position_dodge(width = 0.6)) +
ylab("Delta Log Liklihood (average  per word)") +
xlab("") +
facet_grid(model~lang) +
labs(color = "Eye Movement Measure") +
#scale_x_discrete(labels = c(bquote(w[t-2]), bquote(w[t-1]), bquote(w[t]))) +
#scale_color_manual(values = c("#a1dab4", "#41b6c4", "#225ea8")) +
#ggtitle("Contribution of Surprisal to Î”LL") +
theme(
text = element_text(family="serif"),
legend.position = "bottom",
axis.title.x = element_blank(),
axis.text.x = element_blank()#,
#panel.border = element_rect(color = "grey", fill =  NA, size = 0.5)
)
ggsave("./images/dll_surprisal.pdf", device = "pdf", width = 9.2, height = 4)
# Merge the dataframes
dll_surp_plotting_df = rbind(dll_xlang_surp_df, dll_agg_surp_df)
options(scipen=999)
dll_surp_plotting_df %>%
mutate(lang = factor(lang, levels = c("All", "du", "en", "fi", "ge", "gr", "he", "it", "ko", "ru", "sp", "tr"),
labels = c("All", "Dutch", "English", "Finnish", "German", "Greek", "Hebrew", "Italian", "Korean", "Russian",
"Spanish", "Turkish"))) %>%
filter(model %in% c("mgpt_lc", "monot_all", "monot_30m")) %>%
filter(comp == "target") %>%
rename(target = comp) %>%
mutate(sig = case_when( ttest_pval >= 0.05 ~ " ",
ttest_pval < 0.05 & ttest_pval >= 0.01  ~ "*",
ttest_pval < 0.01 & ttest_pval >= 0.001  ~ "**",
ttest_pval < 0.001  ~ "***")) %>%
mutate(psychometric = case_when(psychometric == "firstfix_rt" ~ "First Fixation",
psychometric == "gaze_rt" ~ "Gaze Duration",
psychometric == "total_rt" ~ "Total Fixation")) %>%
mutate(model = case_when(model == "mgpt_lc" ~ "mGPT",
model == "monot_all" ~ "monoT (all)",
model == "monot_30m" ~ "monoT (30m)")) %>%
mutate(model = factor(model, levels = c("mGPT", "monoT (all)", "monoT (30m)"))) %>%
ggplot(aes(x = psychometric, y = mean, color = psychometric)) +
geom_hline(yintercept=0, color="black", linetype="dashed", alpha =0.5) +
geom_point(position = position_dodge(width = 0.6)) +
geom_text(aes(y = 0.07, label = sig), size = 3, show.legend = FALSE) +
geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.1, position = position_dodge(width = 0.6)) +
ylab("Delta Log Liklihood (average  per word)") +
xlab("") +
facet_grid(model~lang) +
labs(color = "Eye Movement Measure") +
#scale_x_discrete(labels = c(bquote(w[t-2]), bquote(w[t-1]), bquote(w[t]))) +
#scale_color_manual(values = c("#a1dab4", "#41b6c4", "#225ea8")) +
#ggtitle("Contribution of Surprisal to Î”LL") +
theme(
text = element_text(family="serif"),
legend.position = "bottom",
axis.title.x = element_blank(),
axis.text.x = element_blank()#,
#panel.border = element_rect(color = "grey", fill =  NA, size = 0.5)
)
ggsave("./images/dll_surprisal.pdf", device = "pdf", width = 9.2, height = 4)
